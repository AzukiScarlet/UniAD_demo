# UniAD 训练和验证

## 检查nuscense环境和数据集

```shell
./tools/uniad_dist_eval.sh ./projects/configs/stage1_track_map/base_track_map.py ./ckpts/uniad_base_track_map.pth 8
```

如果一切准备就绪，输出结果应该是：

```shell
Aggregated results: 
AMOTA	0.390 
AMOTP	1.300
RECALL	0.489
```

## 训练要求 

两阶段的训练

- stage1: 训练感知模块，50GB GPU内存，8 A100 GPUs，6 epochs，2天
> 节省GPU内存，可以将`queue_length=5`改为`3`，这会略微降低跟踪性能。然后训练将需要约30GB的GPU内存，适用于`V100 GPUs（32GB版本）`。
- stage2: 初始化上一阶段训练的权重，优化所有任务模块，17GB GPU内存，8 A100 GPUs，20 epochs，4天
> 与第一阶段相比，第二阶段需要的GPU内存要少得多，因为我们在这个阶段冻结了BEV编码器，专注于学习特定任务的查询。因此，您可以在`V100或3090`设备上运行第二阶段训练。

## 训练

- 参数1($1): 配置文件路径
- 参数2($2): GPU数量

```shell
# N_GPUS is the number of GPUs used. Recommended >=8.
./tools/uniad_dist_train.sh ./projects/configs/stage1_track_map/base_track_map.py 4
```

## 验证

- 参数1($1): 配置文件路径
- 参数2($2): 模型路径
- 参数3($3): GPU数量

```shell
# N_GPUS is the number of GPUs used.  Recommended =8.
# If you evaluate with different number of GPUs rather than 8, the results might be slightly different.
./tools/uniad_dist_eval.sh ./projects/configs/stage1_track_map/base_track_map.py ./ckpts/uniad_base_track_map.pth 4
```

## 可视化

```shell
python ./tools/analysis_tools/visualize/run.py \
    --predroot /PATH/TO/YOUR/RESULTS.pkl \
    --out_folder /PATH/TO/YOUR/OUTPUT \
    --demo_video test_demo.avi \
    --project_to_cam True
```